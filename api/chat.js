/* =======================================================
   IKED ENGINE: DIAGNOSTIC MODE ğŸ•µï¸â€â™‚ï¸
   Purpose: Reveal the TRUE error message
   ======================================================= */

import { GoogleGenerativeAI } from "@google/generative-ai";

const ALLOWED_ORIGINS = [
    "https://h-app.vercel.app", 
    "http://localhost:3000", 
    "http://127.0.0.1:5500",
    "https://ikedmath-app.vercel.app"
];

/* =======================================================
   DEBUG STRATEGY: TRY EVERYTHING
   ======================================================= */
function selectModelStrategy(query) {
    // Ø³Ù†Ø¬Ø±Ø¨ Ù…ÙˆØ¯ÙŠÙ„Ø§Øª Ù…Ø¹Ø±ÙˆÙØ© Ø¨Ø§Ø³ØªÙ‚Ø±Ø§Ø±Ù‡Ø§ Ø£ÙˆÙ„Ø§Ù‹ Ù„Ù„ØªØ£ÙƒØ¯
    return [
        "gemini-2.0-flash",       // Ø§Ù„Ø¬Ø¯ÙŠØ¯
        "gemini-1.5-flash",       // Ø§Ù„Ù‚Ø¯ÙŠÙ… Ø§Ù„Ù…Ø³ØªÙ‚Ø± (Ù„Ù„ØªØ¬Ø±Ø¨Ø© ÙÙ‚Ø·)
        "gemini-pro"              // Ø§Ù„ÙƒÙ„Ø§Ø³ÙŠÙƒÙŠ
    ];
}

async function generateWithRetry(genAI, modelList, fullPrompt) {
    let debugLog = ""; // Ø³Ø¬Ù„ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡

    for (const modelName of modelList) {
        try {
            debugLog += `\nTrying ${modelName}... `;
            
            const model = genAI.getGenerativeModel({ 
                model: modelName,
                generationConfig: {
                    temperature: 0.6,
                    maxOutputTokens: 2000, 
                }
            }, { apiVersion: 'v1beta' }); // Ø¬Ø±Ø¨Ù†Ø§ v1beta

            const result = await model.generateContentStream(fullPrompt);
            return result.stream;

        } catch (error) {
            // Ø³Ø¬Ù„ Ø§Ù„Ø®Ø·Ø£ Ø¨Ø§Ù„ØªÙØµÙŠÙ„
            debugLog += `âŒ FAILED: ${error.message}. `;
            
            // Ø§Ù†ØªØ¸Ø§Ø± Ù‚ØµÙŠØ±
            await new Promise(r => setTimeout(r, 500));
            continue; 
        }
    }
    // Ø¥Ø°Ø§ ÙˆØµÙ„Ù†Ø§ Ù‡Ù†Ø§ØŒ ÙŠØ¹Ù†ÙŠ ÙƒÙ„Ø´ÙŠ ÙØ´Ù„. Ù†Ø±Ø³Ù„ Ø§Ù„Ø³Ø¬Ù„ ÙƒØ§Ù…Ù„
    throw new Error(`ALL MODELS FAILED. LOGS: ${debugLog}`);
}

export default async function handler(req, res) {
    const origin = req.headers.origin;
    if (ALLOWED_ORIGINS.includes(origin) || !origin) {
        res.setHeader('Access-Control-Allow-Origin', origin || '*');
    }
    res.setHeader('Content-Type', 'text/event-stream');
    res.setHeader('Cache-Control', 'no-cache');
    res.setHeader('Connection', 'keep-alive');

    if (req.method !== 'POST') return res.status(405).json({ error: 'Method Not Allowed' });

    const { prompt } = req.body;
    
    // Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù…ÙØªØ§Ø­
    const apiKey = process.env.GOOGLE_API_KEY;
    if (!apiKey) { 
        res.write(`{"visuals":null}|||STREAM_DIVIDER|||âš ï¸ **FATAL ERROR**: API KEY IS MISSING in Vercel Environment Variables.`);
        res.end(); 
        return; 
    }

    try {
        const genAI = new GoogleGenerativeAI(apiKey);

        const systemInstruction = `You are a helpful assistant. Answer shortly.`;
        const fullPrompt = `${systemInstruction}\n\nUser: ${prompt}`;

        const models = selectModelStrategy(prompt);
        const stream = await generateWithRetry(genAI, models, fullPrompt);

        // Ø¥Ø°Ø§ Ù†Ø¬Ø­ Ø§Ù„Ø§ØªØµØ§Ù„ØŒ Ø³Ù†Ù…Ø± Ù…Ù† Ù‡Ù†Ø§
        let buffer = "";
        let isHeaderSent = false;
        const DIVIDER = "|||STREAM_DIVIDER|||";

        for await (const chunk of stream) {
            const chunkText = chunk.text();
            
            if (!isHeaderSent) {
                // Ù†Ø±Ø³Ù„ Ù‡ÙŠØ¯Ø± ÙØ§Ø±Øº ÙÙ‚Ø· Ù„Ù†Ø®ØªØ¨Ø± Ø§Ù„Ù†Øµ
                res.write(JSON.stringify({ visuals: null }) + DIVIDER);
                isHeaderSent = true;
            }
            res.write(chunkText);
        }
        res.end();

    } catch (error) {
        console.error("Handler Error:", error);
        
        // ğŸ”¥ğŸ”¥ğŸ”¥ Ù‡Ù†Ø§ Ø§Ù„Ø­ÙŠÙ„Ø©: Ø·Ø¨Ø§Ø¹Ø© Ø§Ù„Ø®Ø·Ø£ Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù… ğŸ”¥ğŸ”¥ğŸ”¥
        const errorMsg = `
        ğŸ›‘ **DIAGNOSTIC REPORT** ğŸ›‘
        
        **Error Type:** ${error.name}
        **Message:** ${error.message}
        
        **Possible Causes:**
        1. If "404 Not Found": The model name is wrong.
        2. If "400 Bad Request": The region is blocked or prompt is too long.
        3. If "429 Too Many Requests": Free tier quota exceeded.
        4. If "API Key": Your key is invalid.
        `;
        
        res.write(`{"visuals":null}|||STREAM_DIVIDER|||${errorMsg}`);
        res.end();
    }
}
